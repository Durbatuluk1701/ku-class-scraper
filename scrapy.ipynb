{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import re\n",
    "from datetime import date\n",
    "import http.client as hc\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "def init_argparser() -> argparse.ArgumentParser:\n",
    "    argparser = argparse.ArgumentParser(description=\"Scrappy KU site for class info\")\n",
    "    argparser.add_argument(\"department\", help = \"department code (EECS, CLSX, ...) to look search for\")\n",
    "    argparser.add_argument(\"output\", help = \"file to output results to\")\n",
    "    return argparser\n",
    "\n",
    "semesters = [\"spring\", \"summer\", \"fall\"]\n",
    "\n",
    "def searchTermEncoder(year, semester) -> str:\n",
    "    year = year % 100 # only last 2 digist\n",
    "    if (semester == \"spring\"):\n",
    "        return \"4\" + str(year) + \"2\"\n",
    "    elif (semester == \"summer\"):\n",
    "        return \"4\" + str(year) + \"6\"\n",
    "    else:\n",
    "        return \"4\" + str(year) + \"9\"\n",
    "\n",
    "# https: // classes.ku.edu/Classes/CourseSearch.action?classesSearchText = eecs & searchCareer = UndergraduateGraduate & searchTerm = 4219\n",
    "    \n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     argparser = init_argparser()\n",
    "#     args = argparser.parse_args()\n",
    "#     dept : str = args.department\n",
    "#     output : str = args.output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_url(department: str, searchTerm: str) -> str:\n",
    "    url = f\"https://classes.ku.edu/Classes/CourseSearch.action?classesSearchText={department}&searchCareer=UndergraduateGraduate&searchTerm={searchTerm}\"\n",
    "    # open initial connection\n",
    "    conn = hc.HTTPSConnection(\"classes.ku.edu\")\n",
    "    conn.request(\"GET\", url)\n",
    "    resp = conn.getresponse()\n",
    "    if (resp.status != 200):\n",
    "        raise ConnectionError(\"GET failed\")\n",
    "    return resp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmlText = connect_url(\"eecs\", \"4229\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text : str) -> str:\n",
    "    text = text.replace(\"\\n\",\" \").replace(\"\\t\", \" \").replace(\"\\xa0\", \" \").replace(\"(Save)\",\" \")\n",
    "    while text != text.replace(\"  \", \" \"):\n",
    "        text = text.replace(\"  \", \" \")\n",
    "    text = re.sub(\"^ \", \"\", text)\n",
    "    text = re.sub(\" $\", \"\", text)\n",
    "    return text\n",
    "\n",
    "def parse_table(table) -> tuple[list[str], list[list[str]]]:\n",
    "    headers = table.find_all(\"th\")\n",
    "    headers = [header.get_text() for header in headers]\n",
    "    tableRows = table.find_all(\"tr\")[1:]\n",
    "    tableData = []\n",
    "    for tableRow in tableRows:\n",
    "        tableCols = [clean_text(tableCol.get_text()) for tableCol in tableRow.find_all(\"td\")]\n",
    "        tableData.append(tableCols)\n",
    "    # The last entry of each 2 important rows are not very important\n",
    "    tableData = [tableData[i] for i in range(len(tableData)) if (i % 3 == 0 or i % 3 == 1)]\n",
    "    for i in range(0,len(tableData),2):\n",
    "        tableData[i].append(tableData[i+1][1])\n",
    "    tableData = [tableData[i] for i in range(0,len(tableData),2)]\n",
    "    # Hacky fix\n",
    "    headers[1] = \"Topic/Instructor\"\n",
    "    return (headers + [\"Time/Place\"], tableData)\n",
    "\n",
    "def parse_row(row) -> tuple[str, str, str, list[str], list[list[str]]]:\n",
    "    # return tuple of (className, miniDesc, description)\n",
    "    descRow = row.find_next_sibling(\"tr\")\n",
    "    infoRow = descRow.find_next_sibling(\"tr\")\n",
    "    (headers, tableData) = parse_table(infoRow.find(\"table\"))\n",
    "    className = clean_text(row.find(\"h3\").get_text())\n",
    "    miniDesc = clean_text(row.find(\"td\").get_text())\n",
    "    description = clean_text(descRow.find(\"td\").get_text())\n",
    "    return (className, miniDesc, description, headers, tableData)\n",
    "\n",
    "def parse_html(text: str):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    startBlocks = soup.find_all(\"h3\")\n",
    "    topRows = []\n",
    "    for blk in startBlocks:\n",
    "        topRows.append(blk.parent.parent)\n",
    "    outStuff = {}\n",
    "    for row in topRows:\n",
    "        (name, miniDesc, desc, headers, tableData) = parse_row(row)\n",
    "        outStuff[name] = { \"name\": name, \"miniDesc\": miniDesc, \"description\": desc, \"tableData\": [headers] + tableData }\n",
    "    return outStuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/out2.json\", \"w\") as out_write:\n",
    "    json.dump(parse_html(htmlText), out_write, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateRange(startYear, endYear, startTerm, endTerm) -> list[str]:\n",
    "    startCode = searchTermEncoder(startYear, startTerm)\n",
    "    endCode = searchTermEncoder(endYear, endTerm)\n",
    "    codes = [startCode]\n",
    "    currentCode = startCode\n",
    "    while endCode > currentCode:\n",
    "        (year, term) = (int(currentCode[1:3]), int(currentCode[-1]))\n",
    "        if (term == 2):\n",
    "            term = 6\n",
    "        elif (term == 6):\n",
    "            term = 9\n",
    "        elif (term == 9):\n",
    "            year += 1\n",
    "            term = 2\n",
    "        else:\n",
    "            raise Exception(\"ERROR\")\n",
    "        currentCode = f\"4{year}{term}\"\n",
    "        codes.append(currentCode)\n",
    "    return codes\n",
    "\n",
    "def traverseClasses(department: str, startYear : int, endYear : int, startTerm : str, endTerm : str):\n",
    "    codeRange = generateRange(startYear, endYear, startTerm, endTerm)\n",
    "    bigObject = {}\n",
    "    for code in codeRange:\n",
    "        htmlRes = connect_url(department, code)\n",
    "        classes = parse_html(htmlRes)\n",
    "        bigObject[f\"{department}-{code}\"] = classes\n",
    "    with open(f\"./data/{department}-{codeRange[0]}-{codeRange[-1]}.json\", \"w\") as out_write:\n",
    "        json.dump(bigObject, out_write, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "traverseClasses(\"math\", 21, 23, \"spring\", \"fall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
